Total number of data point sets: 2

#####################
MC ITERATION: 0
#####################


Current run: k_max_train=2000

Train Epoch: [    0/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.199
Train Epoch: [    0/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.091	Val Loss: 3.058
Train Epoch: [    1/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.093
Train Epoch: [    2/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.992
Train Epoch: [    3/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.896
Train Epoch: [    4/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.802
Train Epoch: [    5/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.702
Train Epoch: [    5/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.603	Val Loss: 2.578
Train Epoch: [    6/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.601
Train Epoch: [    7/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.499
Train Epoch: [    8/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.405
Train Epoch: [    9/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.318
Train Epoch: [   10/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.244
Train Epoch: [   10/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.191	Val Loss: 2.181
Train Epoch: [   11/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.191
Train Epoch: [   12/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.157
Train Epoch: [   13/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.143
Train Epoch: [   14/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.147
Train Epoch: [   15/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.160
Train Epoch: [   15/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.173	Val Loss: 2.169
Train Epoch: [   16/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.173
Train Epoch: [   17/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.183
Train Epoch: [   18/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.186
Train Epoch: [   19/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.183
Train Epoch: [   20/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.174
Train Epoch: [   20/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.161	Val Loss: 2.155
Train Epoch: [   21/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.160
Train Epoch: [   22/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.144
Train Epoch: [   23/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.127
Train Epoch: [   24/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.111
Train Epoch: [   25/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.096
Train Epoch: [   25/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.082	Val Loss: 2.070
Train Epoch: [   26/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.082
Train Epoch: [   27/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.067
Train Epoch: [   28/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.057
Train Epoch: [   29/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.047
Train Epoch: [   30/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.037
Train Epoch: [   30/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.028	Val Loss: 2.006
Train Epoch: [   31/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.027
Train Epoch: [   32/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.020
Train Epoch: [   33/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.011
Train Epoch: [   34/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.002
Train Epoch: [   35/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.996
Train Epoch: [   35/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.989	Val Loss: 1.957
Train Epoch: [   36/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.988
Train Epoch: [   37/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.980
Train Epoch: [   38/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.978
Train Epoch: [   39/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.980
Train Epoch: [   40/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.979
Train Epoch: [   40/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.980	Val Loss: 1.949
Train Epoch: [   41/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.983
Train Epoch: [   42/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.981
Train Epoch: [   43/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.982
Train Epoch: [   44/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.980
Train Epoch: [   45/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.976
Train Epoch: [   45/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.976	Val Loss: 1.943
Train Epoch: [   46/  500], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 1.975
Total number of data point sets: 2

#####################
MC ITERATION: 0
#####################


Current run: k_max_train=2000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.322
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.207	Val Loss: 3.111
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.210
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.102
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.999
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.897
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.791
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.687	Val Loss: 2.616
Model parameters: 93442
Marginal Likelihood / point = -2.138
VAF = 2.874%
RMSE y1 = 1.728

Current run: k_max_train=5000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.187
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.082	Val Loss: 2.965
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.081
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.982
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.885
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.789
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.692
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.594	Val Loss: 2.514
Model parameters: 93442
Marginal Likelihood / point = -2.129
VAF = 3.267%
RMSE y1 = 1.722

#####################
MC ITERATION: 1
#####################


Current run: k_max_train=2000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.137
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.031	Val Loss: 3.089
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.035
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.936
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.843
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.750
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.654
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.562	Val Loss: 2.599
Model parameters: 93442
Marginal Likelihood / point = -2.122
VAF = 3.479%
RMSE y1 = 1.717

Current run: k_max_train=5000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.362
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.245	Val Loss: 3.219
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.244
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.136
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.032
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.926
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.818
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.710	Val Loss: 2.692
Model parameters: 93442
Marginal Likelihood / point = -2.131
VAF = 3.017%
RMSE y1 = 1.724

#####################
MC ITERATION: 2
#####################


Current run: k_max_train=2000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.123
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.021	Val Loss: 3.072
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.021
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.926
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.833
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.742
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.648
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.555	Val Loss: 2.590
Model parameters: 93442
Marginal Likelihood / point = -2.123
VAF = 3.699%
RMSE y1 = 1.716

Current run: k_max_train=5000

Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.190
Train Epoch: [    0/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.083	Val Loss: 3.191
Train Epoch: [    1/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 3.083
Train Epoch: [    2/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.984
Train Epoch: [    3/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.888
Train Epoch: [    4/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.792
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.694
Train Epoch: [    5/    5], Batch [     1/     1 (100%)]	Learning rate: 1.00e-03	Loss: 2.595	Val Loss: 2.671
Model parameters: 93442
Total number of data point sets: 2

#####################
MC ITERATION: 0
#####################


Current run: k_max_train=2000

Model parameters: 93442
Marginal Likelihood / point = -2.140
VAF = 2.890%
RMSE y1 = 1.731

Current run: k_max_train=5000

Model parameters: 93442
Marginal Likelihood / point = -2.134
VAF = 3.302%
RMSE y1 = 1.726

#####################
MC ITERATION: 1
#####################


Current run: k_max_train=2000

Model parameters: 93442
Marginal Likelihood / point = -2.123
VAF = 3.532%
RMSE y1 = 1.718

Current run: k_max_train=5000

Model parameters: 93442
Marginal Likelihood / point = -2.123
VAF = 3.072%
RMSE y1 = 1.717
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] on linux
tensor([3.2112, 3.1871])
torch.return_types.sort(
values=tensor([3.1871, 3.2112]),
indices=tensor([1, 0]))
torch.Size([2])
Traceback (most recent call last):
  File "/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File "<input>", line 1, in <module>
NameError: name 'all_val' is not defined
tensor([3.2112, 3.1871])
torch.Size([2])
Traceback (most recent call last):
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/final_narendra_li.py", line 206, in <module>
    path_general)
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/utils/datavisualizer.py", line 121, in plot_perf_varynumdata
    plt.figure(figsize=(5 * 1, 5 * 3))
KeyboardInterrupt
Total number of data point sets: 2

#####################
MC ITERATION: 0
#####################


Current run: k_max_train=2000

Model parameters: 93442
Marginal Likelihood / point = -2.144
VAF = 2.867%
RMSE y1 = 1.734

Current run: k_max_train=5000

Model parameters: 93442
Traceback (most recent call last):
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/final_narendra_li.py", line 175, in <module>
    df = test.run_test(options, loaders, df, path_general, file_name)
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/test.py", line 62, in run_test
    y_sample, y_sample_mu, y_sample_sigma = modelstate.model.generate(u_test)
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/models/dynamic_model.py", line 62, in generate
    y_sample, y_sample_mu, y_sample_sigma = self.m.generate(u)
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/models/model_storn.py", line 174, in generate
    _, h = self.rnn_gen(torch.cat([phi_u_t, phi_z_t], 1).unsqueeze(0), h)
  File "/home/daniel/anaconda3/envs/DeepSSM_SysID/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/daniel/anaconda3/envs/DeepSSM_SysID/lib/python3.7/site-packages/torch/nn/modules/rnn.py", line 729, in forward
    return self.forward_tensor(input, hx)
  File "/home/daniel/anaconda3/envs/DeepSSM_SysID/lib/python3.7/site-packages/torch/nn/modules/rnn.py", line 721, in forward_tensor
    output, hidden = self.forward_impl(input, hx, batch_sizes, max_batch_size, sorted_indices)
  File "/home/daniel/anaconda3/envs/DeepSSM_SysID/lib/python3.7/site-packages/torch/nn/modules/rnn.py", line 699, in forward_impl
    result = self.run_impl(input, hx, batch_sizes)
  File "/home/daniel/anaconda3/envs/DeepSSM_SysID/lib/python3.7/site-packages/torch/nn/modules/rnn.py", line 680, in run_impl
    self.dropout, self.training, self.bidirectional, self.batch_first)
KeyboardInterrupt
Total number of data point sets: 2

#####################
MC ITERATION: 0
#####################


Current run: k_max_train=2000

Model parameters: 93442
Marginal Likelihood / point = -2.127
VAF = 2.898%
RMSE y1 = 1.720

Current run: k_max_train=5000

Model parameters: 93442
Marginal Likelihood / point = -2.127
VAF = 3.346%
RMSE y1 = 1.721

#####################
MC ITERATION: 1
#####################


Current run: k_max_train=2000

Model parameters: 93442
Marginal Likelihood / point = -2.136
VAF = 3.487%
RMSE y1 = 1.729

Current run: k_max_train=5000

Model parameters: 93442
Marginal Likelihood / point = -2.126
VAF = 3.067%
RMSE y1 = 1.721
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] on linux
torch.Size([2, 2])
tensor([[2.8981, 3.3461],
        [3.4872, 3.0667]])
tensor([3.1926, 3.2064])
tensor([0.1735, 0.0390])
tensor([0.4165, 0.1976])
Traceback (most recent call last):
  File "/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File "<string>", line 6, in <module>
NameError: name 'x' is not defined
/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/utils/datavisualizer.py:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
  
/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/utils/datavisualizer.py:31: RuntimeWarning: invalid value encountered in sqrt
  x = np.linspace(0, length - 1, length)
/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/utils/datavisualizer.py:1: RuntimeWarning: invalid value encountered in sqrt
  import matplotlib.pyplot as plt
tensor([nan, nan])
tensor([[-2.1272, -2.1270],
        [-2.1358, -2.1261]])
Traceback (most recent call last):
  File "/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File "<string>", line 2
    x = k_max_train_values
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/final_narendra_li.py", line 206, in <module>
    path_general)
  File "/home/daniel/05_PhD/00_Research/01_Projects/03_LearningDynamics/DeepSSM_SysID/utils/datavisualizer.py", line 127, in plot_perf_varynumdata
    plt.subplot(3, 1, 1)
KeyboardInterrupt
